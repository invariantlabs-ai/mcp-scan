import asyncio
import logging
import os
from collections import defaultdict
from collections.abc import Callable
from typing import Any, List, Dict

from mcp_scan.models import CrossRefResult, ScanError, ScanPathResult, ServerScanResult, EntityScanResult

from .mcp_client import check_server_with_timeout, scan_mcp_config_file
from .StorageFile import StorageFile
from .utils import calculate_distance
from .verify_api import verify_scan_path
from .logger import EnhancedLogger
from .cache import SimpleCache
from .report_generator import ReportGenerator  # â† ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì¶”ê°€

# Set up logger for this module
logger = logging.getLogger(__name__)


class ContextManager:
    def __init__(
        self,
    ):
        logger.debug("Initializing ContextManager")
        self.enabled = True
        self.callbacks = defaultdict(list)
        self.running = []

    def enable(self):
        logger.debug("Enabling ContextManager")
        self.enabled = True

    def disable(self):
        logger.debug("Disabling ContextManager")
        self.enabled = False

    def hook(self, signal: str, async_callback: Callable[[str, Any], None]):
        logger.debug("Registering hook for signal: %s", signal)
        self.callbacks[signal].append(async_callback)

    async def emit(self, signal: str, data: Any):
        if self.enabled:
            logger.debug("Emitting signal: %s", signal)
            for callback in self.callbacks[signal]:
                self.running.append(callback(signal, data))

    async def wait(self):
        logger.debug("Waiting for %d running tasks to complete", len(self.running))
        await asyncio.gather(*self.running)


class MCPScanner:
    def __init__(
        self,
        files: list[str] | None = None,
        base_url: str = "https://mcp.invariantlabs.ai/",
        checks_per_server: int = 1,
        storage_file: str = "~/.mcp-scan",
        server_timeout: int = 10,
        suppress_mcpserver_io: bool = True,
        local_only: bool = False,
        use_cache: bool = True,
        generate_report: bool = False,  # â† ë¦¬í¬íŠ¸ ìƒì„± ì˜µì…˜
        report_path: str = None,        # â† ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
        **kwargs: Any,
    ):
        logger.info("Initializing MCPScanner")
        self.paths = files or []
        logger.debug("Paths to scan: %s", self.paths)
        self.base_url = base_url
        self.checks_per_server = checks_per_server
        self.storage_file_path = os.path.expanduser(storage_file)
        logger.debug("Storage file path: %s", self.storage_file_path)
        self.storage_file = StorageFile(self.storage_file_path)
        self.server_timeout = server_timeout
        self.suppress_mcpserver_io = suppress_mcpserver_io
        self.context_manager = None
        self.local_only = local_only
        
        # Enhanced Logger ì¶”ê°€
        self.enhanced_logger = EnhancedLogger()
        
        # ìºì‹œ ì‹œìŠ¤í…œ ì¶”ê°€
        self.cache = SimpleCache() if use_cache else None
        if use_cache:
            self.enhanced_logger.info("ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ í™œì„±í™”")
        else:
            self.enhanced_logger.info("ğŸš« ìºì‹œ ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
        
        # â† ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì‹œìŠ¤í…œ ì¶”ê°€
        self.report_generator = ReportGenerator() if generate_report else None
        self.report_path = report_path
        
        if generate_report:
            self.enhanced_logger.info("ğŸ“‹ HTML ë¦¬í¬íŠ¸ ìƒì„± í™œì„±í™”")
        
        logger.debug(
            "MCPScanner initialized with timeout: %d, checks_per_server: %d, use_cache: %s, generate_report: %s", 
            server_timeout, checks_per_server, use_cache, generate_report
        )

    def __enter__(self):
        logger.debug("Entering MCPScanner context")
        if self.context_manager is None:
            self.context_manager = ContextManager()
        return self

    async def __aenter__(self):
        logger.debug("Entering MCPScanner async context")
        return self.__enter__()

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        logger.debug("Exiting MCPScanner async context")
        if self.context_manager is not None:
            await self.context_manager.wait()
            self.context_manager = None

    def __exit__(self, exc_type, exc_val, exc_tb):
        logger.debug("Exiting MCPScanner context")
        if self.context_manager is not None:
            asyncio.run(self.context_manager.wait())
            self.context_manager = None

    def hook(self, signal: str, async_callback: Callable[[str, Any], None]):
        logger.debug("Registering hook for signal: %s", signal)
        if self.context_manager is not None:
            self.context_manager.hook(signal, async_callback)
        else:
            error_msg = "Context manager not initialized"
            logger.exception(error_msg)
            raise RuntimeError(error_msg)

    # ìºì‹œëœ ì„¤ì • íŒŒì¼ ìŠ¤ìº”
    async def scan_config_file_with_cache(self, file_path: str) -> ScanPathResult:
        """ì„¤ì • íŒŒì¼ ìŠ¤ìº” (ìºì‹œ ì ìš©)"""
        # ìºì‹œ í™•ì¸
        if self.cache:
            cached_result = self.cache.get(file_path)
            if cached_result:
                self.enhanced_logger.success(f"ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë¡œë“œ: {file_path}")
                # ìºì‹œëœ ë°ì´í„°ë¥¼ ScanPathResult ê°ì²´ë¡œ ë³€í™˜
                try:
                    return ScanPathResult.model_validate(cached_result)
                except Exception as e:
                    self.enhanced_logger.warning(f"ìºì‹œ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨, ìƒˆë¡œ ìŠ¤ìº”: {e}")
                    # ìºì‹œ ë°ì´í„°ê°€ ì†ìƒëœ ê²½ìš° ì‚­ì œ
                    try:
                        cache_key = self.cache._get_cache_key(file_path)
                        cache_file = self.cache.cache_dir / f"{cache_key}.json"
                        if cache_file.exists():
                            cache_file.unlink()
                    except Exception:
                        pass

        # ìƒˆë¡œ ìŠ¤ìº” ìˆ˜í–‰
        self.enhanced_logger.info(f"ğŸ” ìŠ¤ìº” ì‹œì‘: {file_path}")
        result = await self.get_servers_from_path(file_path)
        
        # ìºì‹œì— ì €ì¥ (ì—ëŸ¬ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
        if self.cache and result and not result.error:
            try:
                # ScanPathResultë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                cache_data = result.model_dump()
                if self.cache.set(file_path, cache_data):
                    self.enhanced_logger.info("ğŸ’¾ ìŠ¤ìº” ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                self.enhanced_logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return result

    async def get_servers_from_path(self, path: str) -> ScanPathResult:
        logger.info("Getting servers from path: %s", path)
        result = ScanPathResult(path=path)
        try:
            servers = (await scan_mcp_config_file(path)).get_servers()
            logger.debug("Found %d servers in path: %s", len(servers), path)
            result.servers = [
                ServerScanResult(name=server_name, server=server) for server_name, server in servers.items()
            ]
        except FileNotFoundError as e:
            error_msg = "file does not exist"
            logger.exception("%s: %s", error_msg, path)
            self.enhanced_logger.error(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
            result.error = ScanError(message=error_msg, exception=e)
        except Exception as e:
            error_msg = "could not parse file"
            logger.exception("%s: %s", error_msg, path)
            self.enhanced_logger.error(f"ì„¤ì • íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {path}")
            result.error = ScanError(message=error_msg, exception=e)
        return result

    async def check_server_changed(self, server: ServerScanResult) -> ServerScanResult:
        logger.debug("Checking for changes in server: %s", server.name)
        result = server.model_copy(deep=True)
        for i, (entity, entity_result) in enumerate(server.entities_with_result):
            if entity_result is None:
                continue
            c, messages = self.storage_file.check_and_update(server.name or "", entity, entity_result.verified)
            result.result[i].changed = c
            if c:
                logger.info("Entity %s in server %s has changed", entity.name, server.name)
                self.enhanced_logger.warning(f"ì„œë²„ '{server.name}'ì˜ ì—”í‹°í‹° '{entity.name}'ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤")
                result.result[i].messages.extend(messages)
        return result

    async def check_whitelist(self, server: ServerScanResult) -> ServerScanResult:
        logger.debug("Checking whitelist for server: %s", server.name)
        result = server.model_copy()
        for i, (entity, entity_result) in enumerate(server.entities_with_result):
            if entity_result is None:
                continue
            if self.storage_file.is_whitelisted(entity):
                logger.debug("Entity %s is whitelisted", entity.name)
                result.result[i].whitelisted = True
            else:
                result.result[i].whitelisted = False
        return result

    async def emit(self, signal: str, data: Any):
        logger.debug("Emitting signal: %s", signal)
        if self.context_manager is not None:
            await self.context_manager.emit(signal, data)

    # â† ìƒˆë¡œìš´ ë©”ì„œë“œ: ìŠ¤ìº” ê²°ê³¼ì—ì„œ ì´ìŠˆ ì¶”ì¶œ
    def _extract_issues_from_result(self, result: ServerScanResult) -> List[Dict[str, Any]]:
        """ìŠ¤ìº” ê²°ê³¼ì—ì„œ ì´ìŠˆ ì •ë³´ ì¶”ì¶œí•˜ì—¬ ë¦¬í¬íŠ¸ìš© ë°ì´í„°ë¡œ ë³€í™˜"""
        issues = []
        
        # ê²€ì¦ ì‹¤íŒ¨í•œ ì—”í‹°í‹°ë“¤ì„ ì´ìŠˆë¡œ ì¶”ê°€
        for entity_result in result.result:
            if entity_result and not entity_result.verified:
                severity = 'high' if 'critical' in (entity_result.entity.description or '').lower() else 'medium'
                issues.append({
                    'severity': severity,
                    'description': f"Entity '{entity_result.entity.name}' verification failed",
                    'entity_name': entity_result.entity.name,
                    'entity_type': entity_result.entity.type,
                    'category': 'verification_failure'
                })
        
        # ë³€ê²½ëœ ì—”í‹°í‹°ë“¤ì„ ì´ìŠˆë¡œ ì¶”ê°€
        for entity_result in result.result:
            if entity_result and entity_result.changed:
                issues.append({
                    'severity': 'medium',
                    'description': f"Entity '{entity_result.entity.name}' has been modified since last scan",
                    'entity_name': entity_result.entity.name,
                    'entity_type': entity_result.entity.type,
                    'category': 'entity_changed'
                })
        
        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ì—”í‹°í‹°ë“¤ì„ ë‚®ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆë¡œ ì¶”ê°€
        for entity_result in result.result:
            if entity_result and not entity_result.whitelisted:
                issues.append({
                    'severity': 'low',
                    'description': f"Entity '{entity_result.entity.name}' is not in whitelist",
                    'entity_name': entity_result.entity.name,
                    'entity_type': entity_result.entity.type,
                    'category': 'not_whitelisted'
                })
        
        # ì„œë²„ ì‹œì‘ ì‹¤íŒ¨ë¥¼ ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆë¡œ ì¶”ê°€
        if result.error:
            issues.append({
                'severity': 'high',
                'description': f"Server scan failed: {result.error.message}",
                'error_type': type(result.error.exception).__name__ if result.error.exception else 'Unknown',
                'category': 'server_error'
            })
        
        return issues

    async def scan_server(self, server: ServerScanResult, inspect_only: bool = False) -> ServerScanResult:
        logger.info("Scanning server: %s, inspect_only: %s", server.name, inspect_only)
        result = server.model_copy(deep=True)
        try:
            self.enhanced_logger.info(f"ğŸ” ì„œë²„ ìŠ¤ìº” ì¤‘: {server.name}")
            
            result.signature = await check_server_with_timeout(
                server.server, self.server_timeout, self.suppress_mcpserver_io
            )
            logger.debug(
                "Server %s has %d prompts, %d resources, %d tools",
                server.name,
                len(result.signature.prompts),
                len(result.signature.resources),
                len(result.signature.tools),
            )

            self.enhanced_logger.success(f"ì„œë²„ '{server.name}' ìŠ¤ìº” ì™„ë£Œ")

            if not inspect_only:
                logger.debug("Checking if server has changed: %s", server.name)
                result = await self.check_server_changed(result)
                logger.debug("Checking whitelist for server: %s", server.name)
                result = await self.check_whitelist(result)
                
                # ê²€ì¦ ê²°ê³¼ ì„¤ì •
                if result.signature is not None:
                    result.result = [EntityScanResult(verified=True) for _ in result.signature.entities]
                
        except Exception as e:
            error_msg = "could not start server"
            logger.exception("%s: %s", error_msg, server.name)
            self.enhanced_logger.error(f"ì„œë²„ '{server.name}' ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
            result.error = ScanError(message=error_msg, exception=e)
            if result.signature is not None:
                result.result = [EntityScanResult(verified=False, status=str(e)) for _ in result.signature.entities]
        
        await self.emit("server_scanned", result)
        return result

    async def scan_path(self, path: str, inspect_only: bool = False) -> ScanPathResult:
        logger.info("Scanning path: %s, inspect_only: %s", path, inspect_only)
        
        self.enhanced_logger.info(f"ğŸ“ ê²½ë¡œ ìŠ¤ìº” ì‹œì‘: {path}")
        
        # ìºì‹œ ì ìš©ëœ ì„¤ì • íŒŒì¼ ìŠ¤ìº” ì‚¬ìš©
        if not inspect_only:
            # ì¼ë°˜ ìŠ¤ìº”ì—ì„œëŠ” ìºì‹œ ì‚¬ìš©
            path_result = await self.scan_config_file_with_cache(path)
        else:
            # inspect ëª¨ë“œì—ì„œëŠ” ìºì‹œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í•­ìƒ ìµœì‹  ì •ë³´ í•„ìš”)
            path_result = await self.get_servers_from_path(path)
        
        # ì„œë²„ ì„¤ì • ë¡œë”©ì— ì‹¤íŒ¨í•œ ê²½ìš° ì¡°ê¸° ë¦¬í„´
        if path_result.error:
            return path_result
        
        # ì§„í–‰ë¥  ë°” ì‹œì‘ (ì„œë²„ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        task_id = None
        if path_result.servers:
            total_servers = len(path_result.servers)
            task_id = self.enhanced_logger.start_progress(
                f"MCP ì„œë²„ ìŠ¤ìº” ì¤‘...", 
                total_servers
            )
        
        try:
            for i, server in enumerate(path_result.servers):
                logger.debug("Scanning server %d/%d: %s", i + 1, len(path_result.servers), server.name)
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                if task_id is not None:
                    self.enhanced_logger.update_progress(
                        task_id, 
                        description=f"ìŠ¤ìº” ì¤‘: {server.name}"
                    )
                
                # ì„œë²„ ìŠ¤ìº” ìˆ˜í–‰
                scanned_server = await self.scan_server(server, inspect_only)
                path_result.servers[i] = scanned_server
                
                # ì§„í–‰ë¥  í•œ ë‹¨ê³„ ì „ì§„
                if task_id is not None:
                    self.enhanced_logger.update_progress(task_id)
                    
        finally:
            # ì§„í–‰ë¥  ë°” ì¢…ë£Œ
            if task_id is not None:
                self.enhanced_logger.finish_progress()
        
        # inspect ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ê²€ì¦ ìˆ˜í–‰
        if not inspect_only:
            logger.debug("Verifying server path: %s", path)
            self.enhanced_logger.info("ğŸ” ì„œë²„ ê²€ì¦ ì¤‘...")
            
            # ì„œë²„ ê²€ì¦ ìˆ˜í–‰
            verified_result = await verify_scan_path(path_result, base_url=self.base_url, run_locally=self.local_only)
            verified_result.cross_ref_result = await self.check_cross_references(verified_result)
            
            # ë¦¬í¬íŠ¸ ìƒì„± (ê²€ì¦ í›„ì— ìˆ˜í–‰)
            if self.report_generator:
                for server in verified_result.servers:
                    # ê²€ì¦ ê²°ê³¼ì—ì„œ ì´ìŠˆ ì¶”ì¶œ
                    issues = []
                    if server.result:
                        for entity_result in server.result:
                            if not entity_result.verified:
                                issues.append({
                                    'severity': 'high',
                                    'description': f"Entity '{entity_result.entity.name}' verification failed",
                                    'entity_name': entity_result.entity.name,
                                    'entity_type': entity_result.entity.type,
                                    'category': 'verification_failure'
                                })
                    
                    # ì„œë²„ ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ì´ìŠˆ ì¶”ê°€
                    if server.error:
                        issues.append({
                            'severity': 'high',
                            'description': f"Server scan failed: {server.error.message}",
                            'error_type': type(server.error.exception).__name__ if server.error.exception else 'Unknown',
                            'category': 'server_error'
                        })
                    
                    result_dict = {
                        'issues': issues,
                        'status': 'completed' if not server.error else 'error',
                        'server_info': {
                            'name': server.name,
                            'timeout': self.server_timeout,
                            'total_entities': len(server.entities) if server.signature else 0,
                            'tools_count': len(server.signature.tools) if server.signature else 0,
                            'prompts_count': len(server.signature.prompts) if server.signature else 0,
                            'resources_count': len(server.signature.resources) if server.signature else 0
                        },
                        'scan_metadata': {
                            'timestamp': logger.handlers[0].format(logger.makeRecord(
                                logger.name, logging.INFO, __file__, 0, '', (), None
                            )) if logger.handlers else None,
                            'inspect_only': inspect_only
                        }
                    }
                    self.report_generator.add_scan_result(server.name or 'unknown', result_dict)
            
            # êµì°¨ ì°¸ì¡° ê²°ê³¼ë¥¼ ë¦¬í¬íŠ¸ì— ì¶”ê°€
            if self.report_generator and verified_result.cross_ref_result and verified_result.cross_ref_result.found:
                for server in verified_result.servers:
                    cross_ref_dict = {
                        'issues': [{
                            'severity': 'high',
                            'description': 'Cross-reference security issue detected',
                            'details': verified_result.cross_ref_result.sources,
                            'category': 'cross_reference'
                        }],
                        'status': 'warning',
                        'server_info': {'name': server.name}
                    }
                    if hasattr(self.report_generator, 'scan_results'):
                        for result in self.report_generator.scan_results:
                            if result['server_name'] == server.name:
                                result['result']['issues'].extend(cross_ref_dict['issues'])
                                break
            
            path_result = verified_result
        
        self.enhanced_logger.success(f"ê²½ë¡œ '{path}' ìŠ¤ìº” ì™„ë£Œ")
        
        await self.emit("path_scanned", path_result)
        return path_result

    async def check_cross_references(self, path_result: ScanPathResult) -> CrossRefResult:
        logger.info("Checking cross references for path: %s", path_result.path)
        
        self.enhanced_logger.info("ğŸ”— êµì°¨ ì°¸ì¡° ê²€ì‚¬ ì¤‘...")
        
        cross_ref_result = CrossRefResult(found=False)
        for server in path_result.servers:
            other_servers = [s for s in path_result.servers if s != server]
            other_server_names = [s.name for s in other_servers]
            other_entity_names = [e.name for s in other_servers for e in s.entities]
            flagged_names = set(map(str.lower, other_server_names + other_entity_names))
            logger.debug("Found %d potential cross-reference names", len(flagged_names))

            if len(flagged_names) < 1:
                logger.debug("No flagged names found, skipping cross-reference check")
                continue

            for entity in server.entities:
                tokens = (entity.description or "").lower().split()
                for token in tokens:
                    best_distance = calculate_distance(reference=token, responses=list(flagged_names))[0]
                    if ((best_distance[1] <= 2) and (len(token) >= 5)) or (token in flagged_names):
                        logger.warning("Cross-reference found: %s with token %s", entity.name, token)
                        self.enhanced_logger.warning(f"êµì°¨ ì°¸ì¡° ë°œê²¬: {entity.name} - {token}")
                        cross_ref_result.found = True
                        cross_ref_result.sources.append(f"{entity.name}:{token}")

        if cross_ref_result.found:
            logger.info("Cross references detected with %d sources", len(cross_ref_result.sources))
            self.enhanced_logger.warning(f"âš ï¸ êµì°¨ ì°¸ì¡° {len(cross_ref_result.sources)}ê°œ ë°œê²¬ë¨")
        else:
            logger.debug("No cross references found")
            self.enhanced_logger.success("êµì°¨ ì°¸ì¡° ë¬¸ì œ ì—†ìŒ")
            
        return cross_ref_result

    async def scan(self) -> list[ScanPathResult]:
        logger.info("Starting scan of %d paths", len(self.paths))
        
        self.enhanced_logger.info(f"ğŸš€ MCP ë³´ì•ˆ ìŠ¤ìº” ì‹œì‘ (ì´ {len(self.paths)}ê°œ ê²½ë¡œ)")
        
        # ìºì‹œ í†µê³„ ì¶œë ¥
        if self.cache:
            stats = self.cache.get_cache_stats()
            self.enhanced_logger.info(f"ğŸ“Š ìºì‹œ ìƒíƒœ: ìœ íš¨ ìºì‹œ {stats['ìœ íš¨í•œ ìºì‹œ']}ê°œ, ì´ ìºì‹œ {stats['ì´ ìºì‹œ íŒŒì¼']}ê°œ")
        
        if self.context_manager is not None:
            self.context_manager.disable()

        result_awaited = []
        for i in range(self.checks_per_server):
            logger.debug("Scan iteration %d/%d", i + 1, self.checks_per_server)
            
            if self.checks_per_server > 1:
                self.enhanced_logger.info(f"ìŠ¤ìº” ë°˜ë³µ {i + 1}/{self.checks_per_server}")
            
            # intentionally overwrite and only report the last scan
            if i == self.checks_per_server - 1 and self.context_manager is not None:
                logger.debug("Enabling context manager for final iteration")
                self.context_manager.enable()  # only print on last run
            result = [self.scan_path(path) for path in self.paths]
            result_awaited = await asyncio.gather(*result)

        logger.debug("Saving storage file")
        self.storage_file.save()
        logger.info("Scan completed successfully")
        
        # â† HTML ë¦¬í¬íŠ¸ ìƒì„± ë¡œì§
        if self.report_generator:
            try:
                self.enhanced_logger.info("ğŸ“‹ HTML ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
                report_file = self.report_generator.generate_html_report(self.report_path)
                self.enhanced_logger.success(f"ğŸ“‹ HTML ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
                
                # ë¦¬í¬íŠ¸ ìš”ì•½ ì¶œë ¥
                summary = self.report_generator.generate_summary()
                self.enhanced_logger.print_summary("ğŸ“Š ë¦¬í¬íŠ¸ ìš”ì•½", {
                    "ì´ ì„œë²„": summary['server_stats']['total_servers'],
                    "ì„±ê³µë¥ ": summary['server_stats']['success_rate'], 
                    "ì´ ì´ìŠˆ": summary['issue_stats']['total_issues'],
                    "ë†’ì€ ìœ„í—˜ë„": summary['issue_stats']['high_risk'],
                    "ì¤‘ê°„ ìœ„í—˜ë„": summary['issue_stats']['medium_risk'],
                    "ë‚®ì€ ìœ„í—˜ë„": summary['issue_stats']['low_risk'],
                    "ìŠ¤ìº” ì‹œê°„": summary['timing']['duration'],
                    "ë¦¬í¬íŠ¸ íŒŒì¼": report_file
                })
                
                # ê¶Œì¥ì‚¬í•­ ê°œìˆ˜ ì¶œë ¥
                recommendations = self.report_generator.generate_recommendations(summary)
                critical_recs = len([r for r in recommendations if r['priority'] == 'critical'])
                if critical_recs > 0:
                    self.enhanced_logger.error(f"ğŸš¨ ê¸´ê¸‰ ì¡°ì¹˜ í•„ìš”: {critical_recs}ê°œì˜ ì¤‘ìš” ê¶Œì¥ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                self.enhanced_logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                logger.exception("Report generation failed")
        
        # ì „ì²´ ìŠ¤ìº” ì™„ë£Œ ë° ìš”ì•½ í‘œì‹œ
        total_servers = sum(len(path.servers) for path in result_awaited)
        successful_servers = sum(
            len([s for s in path.servers if s.error is None]) 
            for path in result_awaited
        )
        
        # ìºì‹œ ì„±ëŠ¥ í†µê³„ ì¶”ê°€
        cache_info = {}
        if self.cache:
            stats = self.cache.get_cache_stats()
            cache_info["ìºì‹œ ì ì¤‘"] = f"{stats['ìœ íš¨í•œ ìºì‹œ']}ê°œ"
            cache_info["ì´ ìºì‹œ"] = f"{stats['ì´ ìºì‹œ íŒŒì¼']}ê°œ"
        
        summary_data = {
            "ì´ ê²½ë¡œ ìˆ˜": len(self.paths),
            "ì´ ì„œë²„ ìˆ˜": total_servers,
            "ìŠ¤ìº” ì„±ê³µ": successful_servers,
            "ì„±ê³µë¥ ": f"{(successful_servers/total_servers)*100:.1f}%" if total_servers > 0 else "0%",
            **cache_info
        }
        
        self.enhanced_logger.print_summary("ğŸ‰ ìŠ¤ìº” ì™„ë£Œ", summary_data)
        
        return result_awaited

    async def inspect(self) -> list[ScanPathResult]:
        logger.info("Starting inspection of %d paths", len(self.paths))
        
        self.enhanced_logger.info(f"ğŸ” MCP ì„œë²„ ê²€ì‚¬ ì‹œì‘ (ì´ {len(self.paths)}ê°œ ê²½ë¡œ)")
        
        # inspect ëª¨ë“œì—ì„œëŠ” ë¦¬í¬íŠ¸ ìƒì„±í•˜ì§€ ì•ŠìŒ
        result = [self.scan_path(path, inspect_only=True) for path in self.paths]
        result_awaited = await asyncio.gather(*result)
        
        logger.debug("Saving storage file")
        self.storage_file.save()
        logger.info("Inspection completed successfully")
        
        self.enhanced_logger.success("ğŸ‰ ê²€ì‚¬ ì™„ë£Œ")
        
        return result_awaited